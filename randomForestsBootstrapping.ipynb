{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1727\n",
      "Distribution of safety ratings in 1727 of data:\n",
      "safety\n",
      "med     0.333526\n",
      "high    0.333526\n",
      "low     0.332947\n",
      "Name: proportion, dtype: float64\n",
      "Distribution of safety ratings in bootstrapped sample data:\n",
      "safety\n",
      "med     0.338738\n",
      "high    0.332947\n",
      "low     0.328315\n",
      "Name: proportion, dtype: float64\n",
      "0.3329334105385061\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGwCAYAAACD0J42AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArFElEQVR4nO3dfXiU1Z3/8c+QkCGBZHiSmUQDBIkFGpRnCiiJK4QCKiztooIuVl1hQSRLFcPiQ8pqgqiQVYQCRWB1EbsrWKqIBKsRjApCgvIgDzaRoMTUNp0kggmQ8/vDH7MOASQwkzkJ79d13dfFnPvMme83A+RznblnxmGMMQIAALBIk1AXAAAAcDoCCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdcJDXcCFqKmp0VdffaXo6Gg5HI5QlwMAAM6DMUYVFRWKi4tTkybn3iNpkAHlq6++Unx8fKjLAAAAF6C4uFhXXHHFOec0yIASHR0t6fsGY2JiQlwNAAA4H+Xl5YqPj/f9Hj+XBhlQTr2sExMTQ0ABAKCBOZ/LM7hIFgAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGCd8FAXAKDh6pj+RlDWLZozMijrAmg42EEBAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWCc81AUAwOk6pr8RtLWL5owM2toAAocdFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgnToHlPfee0833XST4uLi5HA49Nprr/nOHT9+XA899JC6d++u5s2bKy4uTv/8z/+sr776ym+NqqoqTZ06VW3btlXz5s1188036/DhwxfdDAAAaBzqHFC+/fZbXXPNNVqwYEGtc0ePHtWOHTv0yCOPaMeOHVqzZo3279+vm2++2W9eWlqa1q5dq9WrV2vLli2qrKzUjTfeqJMnT154JwAAoNGo83fxDB8+XMOHDz/jOZfLpZycHL+x5557Tv369dOhQ4fUvn17eb1eLVu2TC+++KKGDBkiSXrppZcUHx+vTZs2adiwYbXWraqqUlVVle92eXl5XcsGAAANSNCvQfF6vXI4HGrZsqUkafv27Tp+/LhSU1N9c+Li4pSUlKS8vLwzrpGVlSWXy+U74uPjg102AAAIoaAGlO+++07p6ekaN26cYmJiJEklJSWKiIhQq1at/Oa63W6VlJSccZ2ZM2fK6/X6juLi4mCWDQAAQqzOL/Gcr+PHj+vWW29VTU2NFi5c+KPzjTFyOBxnPOd0OuV0OgNdIgAAsFRQdlCOHz+usWPHqrCwUDk5Ob7dE0nyeDyqrq5WWVmZ331KS0vldruDUQ4AAGhgAh5QToWTAwcOaNOmTWrTpo3f+d69e6tp06Z+F9MeOXJEu3bt0sCBAwNdDgAAaIDq/BJPZWWlDh486LtdWFiogoICtW7dWnFxcfrlL3+pHTt26PXXX9fJkyd915W0bt1aERERcrlcuvvuu/XrX/9abdq0UevWrfXAAw+oe/fuvnf1AACAS1udA8rHH3+s66+/3nd7+vTpkqQJEyYoIyND69atkyT16NHD737vvPOOUlJSJEnz589XeHi4xo4dq2PHjumGG27QihUrFBYWdoFtAACAxsRhjDGhLqKuysvL5XK55PV6/a5vAVC/Oqa/EeoS6qxozshQlwBcsury+5vv4gEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsE7QvosHgB0a4luBAYAdFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHT5JFrAEn/gKAP+HHRQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGCdOgeU9957TzfddJPi4uLkcDj02muv+Z03xigjI0NxcXGKjIxUSkqKdu/e7TenqqpKU6dOVdu2bdW8eXPdfPPNOnz48EU1AgAAGo86B5Rvv/1W11xzjRYsWHDG83PnztW8efO0YMECbdu2TR6PR0OHDlVFRYVvTlpamtauXavVq1dry5Ytqqys1I033qiTJ09eeCcAAKDRCK/rHYYPH67hw4ef8ZwxRtnZ2Zo1a5bGjBkjSVq5cqXcbrdWrVqliRMnyuv1atmyZXrxxRc1ZMgQSdJLL72k+Ph4bdq0ScOGDbuIdgAAQGMQ0GtQCgsLVVJSotTUVN+Y0+lUcnKy8vLyJEnbt2/X8ePH/ebExcUpKSnJN+d0VVVVKi8v9zsAAEDjFdCAUlJSIklyu91+426323eupKREERERatWq1VnnnC4rK0sul8t3xMfHB7JsAABgmaC8i8fhcPjdNsbUGjvduebMnDlTXq/XdxQXFwesVgAAYJ+ABhSPxyNJtXZCSktLfbsqHo9H1dXVKisrO+uc0zmdTsXExPgdAACg8QpoQElISJDH41FOTo5vrLq6Wrm5uRo4cKAkqXfv3mratKnfnCNHjmjXrl2+OQAA4NJW53fxVFZW6uDBg77bhYWFKigoUOvWrdW+fXulpaUpMzNTiYmJSkxMVGZmpqKiojRu3DhJksvl0t13361f//rXatOmjVq3bq0HHnhA3bt3972rBwAAXNrqHFA+/vhjXX/99b7b06dPlyRNmDBBK1as0IwZM3Ts2DFNnjxZZWVl6t+/vzZu3Kjo6GjffebPn6/w8HCNHTtWx44d0w033KAVK1YoLCwsAC0BAICGzmGMMaEuoq7Ky8vlcrnk9Xq5HgWNRsf0N0JdwiWhaM7IUJcAXLLq8vub7+IBAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOuGhLgBoSDqmvxHqEnCRgvUcFs0ZGZR1gUsVOygAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgnfBQFwAAjUHH9DeCtnbRnJFBWxuwFTsoAADAOgQUAABgHQIKAACwTsADyokTJ/Twww8rISFBkZGR6tSpk2bPnq2amhrfHGOMMjIyFBcXp8jISKWkpGj37t2BLgUAADRQAQ8oTz75pH77299qwYIF2rt3r+bOnaunnnpKzz33nG/O3LlzNW/ePC1YsEDbtm2Tx+PR0KFDVVFREehyAABAAxTwgPLBBx9o1KhRGjlypDp27Khf/vKXSk1N1ccffyzp+92T7OxszZo1S2PGjFFSUpJWrlypo0ePatWqVYEuBwAANEABDyjXXnut3n77be3fv1+StHPnTm3ZskUjRoyQJBUWFqqkpESpqam++zidTiUnJysvL++Ma1ZVVam8vNzvAAAAjVfAPwfloYcektfrVZcuXRQWFqaTJ0/qiSee0G233SZJKikpkSS53W6/+7ndbn3xxRdnXDMrK0u/+c1vAl0qAACwVMB3UF555RW99NJLWrVqlXbs2KGVK1fq6aef1sqVK/3mORwOv9vGmFpjp8ycOVNer9d3FBcXB7psAABgkYDvoDz44INKT0/XrbfeKknq3r27vvjiC2VlZWnChAnyeDySvt9JiY2N9d2vtLS01q7KKU6nU06nM9ClAgAASwV8B+Xo0aNq0sR/2bCwMN/bjBMSEuTxeJSTk+M7X11drdzcXA0cODDQ5QAAgAYo4DsoN910k5544gm1b99eP/3pT5Wfn6958+bprrvukvT9SztpaWnKzMxUYmKiEhMTlZmZqaioKI0bNy7Q5QAAgAYo4AHlueee0yOPPKLJkyertLRUcXFxmjhxoh599FHfnBkzZujYsWOaPHmyysrK1L9/f23cuFHR0dGBLgcAADRADmOMCXURdVVeXi6XyyWv16uYmJhQl4NLSDC/sRY4G77NGI1FXX5/8108AADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA64aEuAAiGjulvhLoEAMBFYAcFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdPgcFIcNnlQAAzoYdFAAAYJ2gBJQvv/xSt99+u9q0aaOoqCj16NFD27dv9503xigjI0NxcXGKjIxUSkqKdu/eHYxSAABAAxTwgFJWVqZBgwapadOmevPNN7Vnzx4988wzatmypW/O3LlzNW/ePC1YsEDbtm2Tx+PR0KFDVVFREehyAABAAxTwa1CefPJJxcfHa/ny5b6xjh07+v5sjFF2drZmzZqlMWPGSJJWrlwpt9utVatWaeLEiYEuCQAANDAB30FZt26d+vTpo3/6p39Su3bt1LNnTy1dutR3vrCwUCUlJUpNTfWNOZ1OJScnKy8v74xrVlVVqby83O8AAACNV8ADyp///GctWrRIiYmJeuuttzRp0iTdf//9+q//+i9JUklJiSTJ7Xb73c/tdvvOnS4rK0sul8t3xMfHB7psAABgkYAHlJqaGvXq1UuZmZnq2bOnJk6cqH/5l3/RokWL/OY5HA6/28aYWmOnzJw5U16v13cUFxcHumwAAGCRgAeU2NhYdevWzW+sa9euOnTokCTJ4/FIUq3dktLS0lq7Kqc4nU7FxMT4HQAAoPEKeEAZNGiQ9u3b5ze2f/9+dejQQZKUkJAgj8ejnJwc3/nq6mrl5uZq4MCBgS4HAAA0QAF/F8+//du/aeDAgcrMzNTYsWO1detWLVmyREuWLJH0/Us7aWlpyszMVGJiohITE5WZmamoqCiNGzcu0OUAAIAGKOABpW/fvlq7dq1mzpyp2bNnKyEhQdnZ2Ro/frxvzowZM3Ts2DFNnjxZZWVl6t+/vzZu3Kjo6OhAlwMAABoghzHGhLqIuiovL5fL5ZLX6+V6lAaM7+IBzk/RnJGhLgEIiLr8/ua7eAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArBMe6gIAAOfWMf2NoK1dNGdk0NYGLgY7KAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYJ+gBJSsrSw6HQ2lpab4xY4wyMjIUFxenyMhIpaSkaPfu3cEuBQAANBBBDSjbtm3TkiVLdPXVV/uNz507V/PmzdOCBQu0bds2eTweDR06VBUVFcEsBwAANBBBCyiVlZUaP368li5dqlatWvnGjTHKzs7WrFmzNGbMGCUlJWnlypU6evSoVq1adca1qqqqVF5e7ncAAIDGK2gBZcqUKRo5cqSGDBniN15YWKiSkhKlpqb6xpxOp5KTk5WXl3fGtbKysuRyuXxHfHx8sMoGAAAWCEpAWb16tXbs2KGsrKxa50pKSiRJbrfbb9ztdvvOnW7mzJnyer2+o7i4OPBFAwAAa4QHesHi4mJNmzZNGzduVLNmzc46z+Fw+N02xtQaO8XpdMrpdAa0TgAAYK+A76Bs375dpaWl6t27t8LDwxUeHq7c3Fw9++yzCg8P9+2cnL5bUlpaWmtXBQAAXJoCHlBuuOEGffrppyooKPAdffr00fjx41VQUKBOnTrJ4/EoJyfHd5/q6mrl5uZq4MCBgS4HAAA0QAF/iSc6OlpJSUl+Y82bN1ebNm1842lpacrMzFRiYqISExOVmZmpqKgojRs3LtDlAACABijgAeV8zJgxQ8eOHdPkyZNVVlam/v37a+PGjYqOjg5FOQAAwDIOY4wJdRF1VV5eLpfLJa/Xq5iYmFCXgwvUMf2NUJcAXPKK5owMdQm4hNTl9zffxQMAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYJ3wUBcAAAidjulvBGXdojkjg7IuLh3soAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArMPnoOBHBetzEgAAOBt2UAAAgHUIKAAAwDoEFAAAYJ2AB5SsrCz17dtX0dHRateunUaPHq19+/b5zTHGKCMjQ3FxcYqMjFRKSop2794d6FIAAEADFfCAkpubqylTpujDDz9UTk6OTpw4odTUVH377be+OXPnztW8efO0YMECbdu2TR6PR0OHDlVFRUWgywEAAA1QwN/Fs2HDBr/by5cvV7t27bR9+3YNHjxYxhhlZ2dr1qxZGjNmjCRp5cqVcrvdWrVqlSZOnBjokgAAQAMT9GtQvF6vJKl169aSpMLCQpWUlCg1NdU3x+l0Kjk5WXl5eWdco6qqSuXl5X4HAABovIIaUIwxmj59uq699lolJSVJkkpKSiRJbrfbb67b7fadO11WVpZcLpfviI+PD2bZAAAgxIIaUO677z598sknevnll2udczgcfreNMbXGTpk5c6a8Xq/vKC4uDkq9AADADkH7JNmpU6dq3bp1eu+993TFFVf4xj0ej6Tvd1JiY2N946WlpbV2VU5xOp1yOp3BKhUAAFgm4Dsoxhjdd999WrNmjf70pz8pISHB73xCQoI8Ho9ycnJ8Y9XV1crNzdXAgQMDXQ4AAGiAAr6DMmXKFK1atUp/+MMfFB0d7buuxOVyKTIyUg6HQ2lpacrMzFRiYqISExOVmZmpqKgojRs3LtDlAACABijgAWXRokWSpJSUFL/x5cuX684775QkzZgxQ8eOHdPkyZNVVlam/v37a+PGjYqOjg50OQAAoAEKeEAxxvzoHIfDoYyMDGVkZAT64QEAQCPAd/EAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgnfBQFwAAaHw6pr8RtLWL5owM2tqwBzsoAADAOgQUAABgHV7iaSSCuZ0KAEB9YwcFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOvwZYFnwBfvAYC9gvV/dNGckUFZFxeGHRQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOuENKAsXLhQCQkJatasmXr37q3NmzeHshwAAGCJkH0OyiuvvKK0tDQtXLhQgwYN0uLFizV8+HDt2bNH7du3D1VZAAAEXEP8fK1Qfy5MyHZQ5s2bp7vvvlv33HOPunbtquzsbMXHx2vRokWhKgkAAFgiJDso1dXV2r59u9LT0/3GU1NTlZeXV2t+VVWVqqqqfLe9Xq8kqby8PCj11VQdDcq6AAB7Bet3itQwf68E4+dxak1jzI/ODUlA+eabb3Ty5Em53W6/cbfbrZKSklrzs7Ky9Jvf/KbWeHx8fNBqBABcWlzZoa7ALsH8eVRUVMjlcp1zTki/i8fhcPjdNsbUGpOkmTNnavr06b7bNTU1+tvf/qY2bdqccX59KC8vV3x8vIqLixUTExOSGuoLvTY+l0qf0qXT66XSp3Tp9NoY+zTGqKKiQnFxcT86NyQBpW3btgoLC6u1W1JaWlprV0WSnE6nnE6n31jLli2DWeJ5i4mJaTR/cX4MvTY+l0qf0qXT66XSp3Tp9NrY+vyxnZNTQnKRbEREhHr37q2cnBy/8ZycHA0cODAUJQEAAIuE7CWe6dOn64477lCfPn00YMAALVmyRIcOHdKkSZNCVRIAALBEyALKLbfcor/+9a+aPXu2jhw5oqSkJK1fv14dOnQIVUl14nQ69dhjj9V66akxotfG51LpU7p0er1U+pQunV4vlT7PxmHO570+AAAA9Yjv4gEAANYhoAAAAOsQUAAAgHUIKAAAwDoElB9YuHChEhIS1KxZM/Xu3VubN28+69wtW7Zo0KBBatOmjSIjI9WlSxfNnz+/1rxXX31V3bp1k9PpVLdu3bR27dpgtnBeAt3n7t279Ytf/EIdO3aUw+FQdnZ2kDs4f4HudenSpbruuuvUqlUrtWrVSkOGDNHWrVuD3caPCnSfa9asUZ8+fdSyZUs1b95cPXr00IsvvhjsNs5LMP6dnrJ69Wo5HA6NHj06CJXXXaB7XbFihRwOR63ju+++C3Yr5xSM5/Tvf/+7pkyZotjYWDVr1kxdu3bV+vXrg9nGeQl0rykpKWd8TkeODO03EQeEgTHGmNWrV5umTZuapUuXmj179php06aZ5s2bmy+++OKM83fs2GFWrVpldu3aZQoLC82LL75ooqKizOLFi31z8vLyTFhYmMnMzDR79+41mZmZJjw83Hz44Yf11VYtwehz69at5oEHHjAvv/yy8Xg8Zv78+fXUzbkFo9dx48aZ559/3uTn55u9e/eaX/3qV8blcpnDhw/XV1u1BKPPd955x6xZs8bs2bPHHDx40GRnZ5uwsDCzYcOG+mrrjILR6ylFRUXm8ssvN9ddd50ZNWpUkDv5ccHodfny5SYmJsYcOXLE7wilYPRZVVVl+vTpY0aMGGG2bNliioqKzObNm01BQUF9tXVGwej1r3/9q99zuWvXLhMWFmaWL19eT10FDwHl/+vXr5+ZNGmS31iXLl1Menr6ea/xj//4j+b222/33R47dqz5+c9/7jdn2LBh5tZbb724Yi9CMPr8oQ4dOlgTUILdqzHGnDhxwkRHR5uVK1decJ0Xqz76NMaYnj17mocffviCagyUYPV64sQJM2jQIPO73/3OTJgwwYqAEoxely9fblwuV6BKDIhg9Llo0SLTqVMnU11dHbA6A6E+/q3Onz/fREdHm8rKyguu0xa8xCOpurpa27dvV2pqqt94amqq8vLyzmuN/Px85eXlKTk52Tf2wQcf1Fpz2LBh571moAWrTxvVV69Hjx7V8ePH1bp164uq90LVR5/GGL399tvat2+fBg8efNE1X6hg9jp79mxddtlluvvuuwNW78UIZq+VlZXq0KGDrrjiCt14443Kz88PWN11Faw+161bpwEDBmjKlClyu91KSkpSZmamTp48GdD666K+/k9atmyZbr31VjVv3vyi6rVBSL/N2BbffPONTp48WeuLCt1ud60vNDzdFVdcob/85S86ceKEMjIydM899/jOlZSUXNCawRKsPm1UX72mp6fr8ssv15AhQwJSd10Fs0+v16vLL79cVVVVCgsL08KFCzV06NCA93C+gtXr+++/r2XLlqmgoCAYZV+QYPXapUsXrVixQt27d1d5ebn+8z//U4MGDdLOnTuVmJgYlF7OJVh9/vnPf9af/vQnjR8/XuvXr9eBAwc0ZcoUnThxQo8++mhQevkx9fF/0tatW7Vr1y4tW7YsYHWHEgHlBxwOh99tY0ytsdNt3rxZlZWV+vDDD5Wenq7OnTvrtttuu6g1gy0YfdoqmL3OnTtXL7/8st599101a9YsoHXXVTD6jI6OVkFBgSorK/X2229r+vTp6tSpk1JSUoLRwnkLZK8VFRW6/fbbtXTpUrVt2zaYZV+QQD+vP/vZz/Szn/3MN3fQoEHq1auXnnvuOT377LOBb+A8BbrPmpoatWvXTkuWLFFYWJh69+6tr776Sk899VTIAsopwfw/admyZUpKSlK/fv0CWnOoEFAktW3bVmFhYbVSbGlpaa20e7qEhARJUvfu3fX1118rIyPD9xfH4/Fc0JrBEqw+bRTsXp9++mllZmZq06ZNuvrqqwNbfB0Es88mTZqoc+fOkqQePXpo7969ysrKCllACUavn3/+uYqKinTTTTf55tbU1EiSwsPDtW/fPl155ZUB7uTH1de/1SZNmqhv3746cOBAYAqvo2D1GRsbq6ZNmyosLMw3v2vXriopKVF1dbUiIiIC3MmPC/ZzevToUa1evVqzZ88ObOEhxDUokiIiItS7d2/l5OT4jefk5GjgwIHnvY4xRlVVVb7bAwYMqLXmxo0b67RmIAWrTxsFs9ennnpK//Ef/6ENGzaoT58+Aan3QtXncxrq5z0YvXbp0kWffvqpCgoKfMfNN9+s66+/XgUFBYqPjw9oD+ervp5XY4wKCgoUGxt7wbVejGD1OWjQIB08eNAXNiVp//79io2NDUk4kYL/nP7+979XVVWVbr/99ouu1Rr1e02uvU69/WvZsmVmz549Ji0tzTRv3twUFRUZY4xJT083d9xxh2/+ggULzLp168z+/fvN/v37zQsvvGBiYmLMrFmzfHPef/99ExYWZubMmWP27t1r5syZY83bjAPZZ1VVlcnPzzf5+fkmNjbWPPDAAyY/P98cOHCg3vv7oWD0+uSTT5qIiAjzv//7v35v7auoqKj3/k4JRp+ZmZlm48aN5vPPPzd79+41zzzzjAkPDzdLly6t9/5+KBi9ns6Wd/EEo9eMjAyzYcMG8/nnn5v8/Hzzq1/9yoSHh5uPPvqo3vs7JRh9Hjp0yLRo0cLcd999Zt++feb111837dq1M48//ni99/dDwfz7e+2115pbbrml3nqpDwSUH3j++edNhw4dTEREhOnVq5fJzc31nZswYYJJTk723X722WfNT3/6UxMVFWViYmJMz549zcKFC83Jkyf91vyf//kf85Of/MQ0bdrUdOnSxbz66qv11c5ZBbrPwsJCI6nW8cN1QiXQvXbo0OGMvT722GP12FVtge5z1qxZpnPnzqZZs2amVatWZsCAAWb16tX12dJZBePf6Q/ZElCMCXyvaWlppn379iYiIsJcdtllJjU11eTl5dVnS2cUjOc0Ly/P9O/f3zidTtOpUyfzxBNPmBMnTtRXS2cVjF737dtnJJmNGzfWVxv1wmGMMSHavAEAADgjrkEBAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAN2J133qnRo0eH7PE7duwoh8Mhh8OhqKgoJSUlafHixSGr53wVFRXJ4XCooKAg1KUAOAsCCoCLMnv2bB05ckSffPKJRo8erUmTJumVV165oLWOHz8e4OoANFQEFKARy83NVb9+/eR0OhUbG6v09HSdOHFCkvTHP/5RLVu29H0lfUFBgRwOhx588EHf/SdOnKjbbrvtnI8RHR0tj8ejzp076/HHH1diYqJee+01SZLX69W9996rdu3aKSYmRv/wD/+gnTt3+u6bkZGhHj166IUXXlCnTp3kdDpljNHf//533XvvvXK73WrWrJmSkpL0+uuv++6Xl5enwYMHKzIyUvHx8br//vv17bff+s537NhRmZmZuuuuuxQdHa327dtryZIlvvMJCQmSpJ49e8rhcCglJUWStG3bNg0dOlRt27aVy+VScnKyduzY4dfvZ599pmuvvVbNmjVTt27dtGnTJjkcDl/PkvTll1/qlltuUatWrdSmTRuNGjVKRUVFP/JsAfghAgrQSH355ZcaMWKE+vbtq507d2rRokVatmyZHn/8cUnS4MGDVVFRofz8fEnfh5m2bdsqNzfXt8a7776r5OTkOj1us2bNdPz4cRljNHLkSJWUlGj9+vXavn27evXqpRtuuEF/+9vffPMPHjyo3//+93r11VdVUFCgmpoaDR8+XHl5eXrppZe0Z88ezZkzR2FhYZKkTz/9VMOGDdOYMWP0ySef6JVXXtGWLVt03333+dXxzDPPqE+fPsrPz9fkyZP1r//6r/rss88kSVu3bpUkbdq0SUeOHNGaNWskSRUVFZowYYI2b96sDz/8UImJiRoxYoQqKiokSTU1NRo9erSioqL00UcfacmSJZo1a5bf4x49elTXX3+9WrRooffee09btmxRixYt9POf/1zV1dV1+lkCl7TQfpkygIsxYcIEM2rUqDOe+/d//3fzk5/8xNTU1PjGnn/+edOiRQvf17X36tXLPP3008YYY0aPHm2eeOIJExERYcrLy82RI0eMJLN3796zPn6HDh3M/PnzjTHGHD9+3CxfvtxIMgsXLjRvv/22iYmJMd99953ffa688kqzePFiY4wxjz32mGnatKkpLS31nX/rrbdMkyZNzL59+874mHfccYe59957/cY2b95smjRpYo4dO+ar6/bbb/edr6mpMe3atTOLFi0yxhhTWFhoJJn8/Pyz9maMMSdOnDDR0dHmj3/8ozHGmDfffNOEh4ebI0eO+Obk5OQYSWbt2rXGGGOWLVtW6+deVVVlIiMjzVtvvXXOxwPwf9hBARqpvXv3asCAAXI4HL6xQYMGqbKyUocPH5YkpaSk6N1335UxRps3b9aoUaOUlJSkLVu26J133pHb7VaXLl3O+TgPPfSQWrRoocjISE2ZMkUPPvigJk6cqO3bt6uyslJt2rRRixYtfEdhYaE+//xz3/07dOigyy67zHe7oKBAV1xxha666qozPt727du1YsUKvzWHDRummpoaFRYW+uZdffXVvj87HA55PB6Vlpaes5fS0lJNmjRJV111lVwul1wulyorK3Xo0CFJ0r59+xQfHy+Px+O7T79+/WrVd/DgQUVHR/vqa926tb777ju/vgGcW3ioCwAQHMYYv3ByakySbzwlJUXLli3Tzp071aRJE3Xr1k3JycnKzc1VWVnZeb288+CDD+rOO+9UVFSUYmNjfWvX1NQoNjZW7777bq37tGzZ0vfn5s2b+52LjIw85+PV1NRo4sSJuv/++2uda9++ve/PTZs29TvncDh819uczZ133qm//OUvys7OVocOHeR0OjVgwADfSzNn+pmeqb7evXvrv//7v2ud+2EQA3BuBBSgkerWrZteffVVv1+qeXl5io6O1uWXXy7p/65Dyc7OVnJyshwOh5KTk5WVlaWysjJNmzbtRx+nbdu26ty5c63xXr16qaSkROHh4erYseN513311Vfr8OHD2r9//xl3UXr16qXdu3ef8THPV0REhCTp5MmTfuObN2/WwoULNWLECElScXGxvvnmG9/5Ll266NChQ/r666/ldrslfX9h7en1vfLKK74LgwFcGF7iARo4r9ergoICv+PQoUOaPHmyiouLNXXqVH322Wf6wx/+oMcee0zTp09Xkybf/9N3uVzq0aOHXnrpJd87WQYPHqwdO3Zo//79vrELMWTIEA0YMECjR4/WW2+9paKiIuXl5enhhx/Wxx9/fNb7JScna/DgwfrFL36hnJwcFRYW6s0339SGDRskff+S0gcffKApU6aooKBABw4c0Lp16zR16tTzrq1du3aKjIzUhg0b9PXXX8vr9UqSOnfurBdffFF79+7VRx99pPHjx/vt6AwdOlRXXnmlJkyYoE8++UTvv/++7yLZUyFw/Pjxatu2rUaNGqXNmzersLBQubm5mjZtmu+lNQA/joACNHDvvvuuevbs6Xc8+uijuvzyy7V+/Xpt3bpV11xzjSZNmqS7775bDz/8sN/9r7/+ep08edIXRlq1aqVu3brpsssuU9euXS+4LofDofXr12vw4MG66667dNVVV+nWW29VUVGRb/fhbF599VX17dtXt912m7p166YZM2b4djuuvvpq5ebm6sCBA7ruuuvUs2dPPfLII4qNjT3v2sLDw/Xss89q8eLFiouL06hRoyRJL7zwgsrKytSzZ0/dcccduv/++9WuXTvf/cLCwvTaa6+psrJSffv21T333OP7eTZr1kySFBUVpffee0/t27fXmDFj1LVrV9111106duwYOypAHTjMqRelAQB19v777+vaa6/VwYMHdeWVV4a6HKDRIKAAQB2sXbtWLVq0UGJiog4ePKhp06apVatW2rJlS6hLAxoVLpIFgDqoqKjQjBkzVFxcrLZt22rIkCF65plnQl0W0OiwgwIAAKzDRbIAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHX+H/M7iN38/P4xAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average low percentage: 0.3329\n",
      "95% Confidence Interval for low percengage: (0.3115,0.3538)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Models from scikit learn module:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df = pd.read_csv('data/car_evaluation.csv')\n",
    "\n",
    "#df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "df['accep'] = ~(df.iloc[:, 6]=='unacc')\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "nrows = df.shape[0]\n",
    "\n",
    "df['safety'] = df.iloc[:, 5]\n",
    "\n",
    "## 1. Print number of rows and distribution of safety ratings\n",
    "print(nrows)\n",
    "print(f'Distribution of safety ratings in {nrows} of data:')\n",
    "print(df.safety.value_counts(normalize=True))\n",
    "\n",
    "## 2. Create bootstrapped sample\n",
    "boot_sample = df.sample(nrows, replace=True)\n",
    "print(f'Distribution of safety ratings in bootstrapped sample data:')\n",
    "print(boot_sample.safety.value_counts(normalize=True))\n",
    "\n",
    "\n",
    "## 3. Create 1000 bootstrapped samples\n",
    "low_perc = []\n",
    "for i in range(1000):\n",
    "    boot_sample = df.sample(nrows, replace=True)\n",
    "    low_perc.append(boot_sample.safety.value_counts(normalize=True)['low'])\n",
    "\n",
    "## 4. Plot a histogram of the low percentage values\n",
    "mean_lp = np.mean(low_perc) \n",
    "print(mean_lp)\n",
    "plt.hist(low_perc, bins=20);\n",
    "plt.xlabel('Low Percentage')\n",
    "plt.show()\n",
    "\n",
    "## 5. What are the 2.5 and 97.5 percentiles?\n",
    "print(f'Average low percentage: {np.mean(low_perc).round(4)}')\n",
    "\n",
    "low_perc.sort()\n",
    "print(f'95% Confidence Interval for low percengage: ({low_perc[25].round(4)},{low_perc[975].round(4)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of DT on test set (trained using full set): 0.8588\n",
      "Accuracy score of DT on test set (trained using bootstrapped sample): 0.8912\n",
      "Accuracy score of aggregated 10 bootstrapped samples:0.9097\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "#df = pd.read_csv('data/car_evaluation.csv')\n",
    "#df['accep'] = ~(df.iloc[:, 6]=='unacc')\n",
    "\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "\n",
    "#original decision tree trained on full training set\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(x_train, y_train)\n",
    "#print(f'Accuracy score of DT on test set (trained using full set): {dt.score(x_test, y_test).round(4)}')\n",
    "print(f'Accuracy score of DT on test set (trained using full set): {round(dt.score(x_test, y_test), 4)}')\n",
    "\n",
    "\n",
    "#2. New decision tree trained on bootstrapped sample\n",
    "dt2 = DecisionTreeClassifier(max_depth=5)\n",
    "#ids are the indices of the bootstrapped sample\n",
    "ids = x_train.sample(x_train.shape[0], replace=True, random_state=0).index\n",
    "dt2.fit(x_train.loc[ids], y_train[ids])#max_depth=50,criterion='gini')\n",
    "print(f'Accuracy score of DT on test set (trained using bootstrapped sample): {round(dt2.score(x_test, y_test), 4)}')\n",
    "\n",
    "## 3. Bootstapping ten samples and aggregating the results:\n",
    "preds = []\n",
    "random_state = 0\n",
    "for i in range(10):\n",
    "    ids = x_train.sample(x_train.shape[0], replace=True, random_state=random_state+i).index\n",
    "    dt2.fit(x_train.loc[ids], y_train[ids])\n",
    "    preds.append(dt2.predict(x_test))   \n",
    "ba_pred = np.array(preds).mean(0)\n",
    "\n",
    "# 4. Calculate accuracy of the bagged sample\n",
    "ba_accuracy = accuracy_score(ba_pred>=0.5, y_test)\n",
    "print(f'Accuracy score of aggregated 10 bootstrapped samples:{round(ba_accuracy, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of DT on test set (trained using full feature set):\n",
      "0.9444444444444444\n",
      "Accuracy score of DT on test set (trained using random feature sample):\n",
      "0.9027777777777778\n",
      "Accuracy score of aggregated 10 samples:\n",
      "0.7384259259259259\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "print(\"Accuracy score of DT on test set (trained using full feature set):\")\n",
    "accuracy_dt = dt.score(x_test, y_test)\n",
    "print(accuracy_dt)\n",
    "\n",
    "# 1. Create rand_features, random samples from the set of features\n",
    "rand_features = np.random.choice(x_train.columns,10)\n",
    "\n",
    "# Make new decision tree trained on random sample of 10 features and calculate the new accuracy score\n",
    "dt2 = DecisionTreeClassifier()\n",
    "\n",
    "dt2.fit(x_train[rand_features], y_train)\n",
    "print(\"Accuracy score of DT on test set (trained using random feature sample):\")\n",
    "accuracy_dt2 = dt2.score(x_test[rand_features], y_test)\n",
    "print(accuracy_dt2)\n",
    "\n",
    "# 2. Build decision trees on 10 different random samples \n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    rand_features = np.random.choice(x_train.columns,10)\n",
    "    dt2.fit(x_train[rand_features], y_train)\n",
    "    predictions.append(dt2.predict(x_test[rand_features]))\n",
    "\n",
    "## 3. Get aggregate predictions and accuracy score\n",
    "prob_predictions = np.array(predictions).mean(0)\n",
    "agg_predictions = (prob_predictions>0.5)\n",
    "agg_accuracy = accuracy_score(agg_predictions, y_test)\n",
    "print('Accuracy score of aggregated 10 samples:')\n",
    "print(agg_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Bagged Classifier, 10 estimators:\n",
      "0.9027777777777778\n",
      "Accuracy score of Bagged Classifier, 10 estimators, 10 max features:\n",
      "0.8981481481481481\n",
      "Accuracy score of Logistic Regression, 10 estimators:\n",
      "0.8912037037037037\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 1. Bagging classifier with 10 Decision Tree base estimators\n",
    "bag_dt = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=5), n_estimators=10)\n",
    "bag_dt.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracy score of Bagged Classifier, 10 estimators:')\n",
    "bag_accuracy = bag_dt.score(x_test, y_test)\n",
    "print(bag_accuracy)\n",
    "\n",
    "# 2.Set `max_features` to 10.\n",
    "bag_dt_10 = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=5), n_estimators=10, max_features=10)\n",
    "bag_dt_10.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracy score of Bagged Classifier, 10 estimators, 10 max features:')\n",
    "bag_accuracy_10 = bag_dt_10.score(x_test, y_test)\n",
    "print(bag_accuracy_10)\n",
    "\n",
    "\n",
    "# 3. Change base estimator to Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "bag_lr = BaggingClassifier(estimator=LogisticRegression(),\n",
    "                         n_estimators=10, max_features=10)\n",
    "bag_lr.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracy score of Logistic Regression, 10 estimators:')\n",
    "bag_accuracy_lr = bag_lr.score(x_test, y_test)\n",
    "print(bag_accuracy_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Predict using `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Test set accuracy:\n",
      "0.9490740740740741\n",
      "Test set precision: 0.9384615384615385\n",
      "Test set recall: 0.8970588235294118\n",
      "Test set confusion matrix:\n",
      "[[288   8]\n",
      " [ 14 122]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 1. Create a Random Forest Classifier and print its parameters\n",
    "rf = RandomForestClassifier()\n",
    "print('Random Forest parameters:')\n",
    "rf_params = rf.get_params()\n",
    "print(rf_params)\n",
    "\n",
    "# 2. Fit the Random Forest Classifier to training data and calculate accuracy score on the test data\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print('Test set accuracy:')\n",
    "rf_accuracy = rf.score(x_test, y_test)\n",
    "print(rf_accuracy)\n",
    "\n",
    "# 3. Calculate Precision and Recall scores and the Confusion Matrix\n",
    "rf_precision = precision_score(y_test, y_pred)\n",
    "print(f'Test set precision: {rf_precision}')\n",
    "rf_recall = recall_score(y_test, y_pred)\n",
    "print(f'Test set recall: {rf_recall}')\n",
    "rf_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Test set confusion matrix:\\n{rf_confusion_matrix}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     1728.000000\n",
      "mean     36710.488990\n",
      "std      13292.159198\n",
      "min       5174.902339\n",
      "25%      25717.386389\n",
      "50%      37101.325269\n",
      "75%      47567.872101\n",
      "max      68309.310911\n",
      "Name: price, dtype: float64\n",
      "Train set R^2: 0.9756322260254321\n",
      "Test set R^2: 0.8349362918957832\n",
      "Avg Price Train/Test: 36710.488990304766\n",
      "Train set MAE: 1622.8212125332702\n",
      "Test set MAE: 4348.138853315431\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "\n",
    "## Generating some fake prices for regression! :) \n",
    "fake_prices = (15000 + 25*df.index.values)+np.random.normal(size=df.shape[0])*5000\n",
    "df['price'] = fake_prices\n",
    "print(df.price.describe())\n",
    "y = df['price']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 1. Create a Random Regressor and print `R^2` scores on training and test data\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(x_train, y_train)\n",
    "\n",
    "r_squared_train = rfr.score(x_train, y_train)\n",
    "print(f'Train set R^2: {r_squared_train}')\n",
    "\n",
    "r_squared_test = rfr.score(x_test, y_test)\n",
    "print(f'Test set R^2: {r_squared_test}')\n",
    "\n",
    "# 2. Print Mean Absolute Error on training and test data\n",
    "\n",
    "avg_price = y.mean()\n",
    "print(f'Avg Price Train/Test: {avg_price}')\n",
    "\n",
    "y_pred_train =rfr.predict(x_train)\n",
    "y_pred_test =rfr.predict(x_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(f'Train set MAE: {mae_train}')\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(f'Test set MAE: {mae_test}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
